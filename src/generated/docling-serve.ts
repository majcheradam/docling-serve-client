/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
  "/openapi-3.0.json": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Openapi 30 */
    get: operations["openapi_30_openapi_3_0_json_get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/health": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Health */
    get: operations["health_health_get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/convert/source": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Process Url */
    post: operations["process_url_v1_convert_source_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/convert/file": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Process File */
    post: operations["process_file_v1_convert_file_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/convert/source/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Process Url Async */
    post: operations["process_url_async_v1_convert_source_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/convert/file/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Process File Async */
    post: operations["process_file_async_v1_convert_file_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hybrid/source/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Sources With Hybridchunker As Async Task */
    post: operations["Chunk_sources_with_HybridChunker_as_async_task_v1_chunk_hybrid_source_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hybrid/file/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Files With Hybridchunker As Async Task */
    post: operations["Chunk_files_with_HybridChunker_as_async_task_v1_chunk_hybrid_file_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hybrid/source": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Sources With Hybridchunker */
    post: operations["Chunk_sources_with_HybridChunker_v1_chunk_hybrid_source_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hybrid/file": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Files With Hybridchunker */
    post: operations["Chunk_files_with_HybridChunker_v1_chunk_hybrid_file_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hierarchical/source/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Sources With Hierarchicalchunker As Async Task */
    post: operations["Chunk_sources_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_source_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hierarchical/file/async": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Files With Hierarchicalchunker As Async Task */
    post: operations["Chunk_files_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_file_async_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hierarchical/source": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Sources With Hierarchicalchunker */
    post: operations["Chunk_sources_with_HierarchicalChunker_v1_chunk_hierarchical_source_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chunk/hierarchical/file": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chunk Files With Hierarchicalchunker */
    post: operations["Chunk_files_with_HierarchicalChunker_v1_chunk_hierarchical_file_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/status/poll/{task_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Task Status Poll */
    get: operations["task_status_poll_v1_status_poll__task_id__get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/result/{task_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Task Result */
    get: operations["task_result_v1_result__task_id__get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/clear/converters": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Clear Converters */
    get: operations["clear_converters_v1_clear_converters_get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/clear/results": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Clear Results */
    get: operations["clear_results_v1_clear_results_get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
}
export type webhooks = Record<string, never>;
export interface components {
  schemas: {
    /** Body_Chunk_files_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_file_async_post */
    Body_Chunk_files_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_file_async_post: {
      /** Files */
      files: string[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * @description Specification for the type of output target.
       * @default inbody
       */
      target_type: components["schemas"]["TargetName"];
      /**
       * Convert From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      convert_from_formats: components["schemas"]["InputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      convert_image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Convert Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      convert_do_ocr: boolean;
      /**
       * Convert Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      convert_ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Convert Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      convert_ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      convert_pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      convert_table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Convert Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      convert_table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      convert_pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Convert Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      convert_page_range: [number, number];
      /**
       * Convert Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      convert_document_timeout: number;
      /**
       * Convert Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_abort_on_error: boolean;
      /**
       * Convert Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_do_table_structure: boolean;
      /**
       * Convert Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_include_images: boolean;
      /**
       * Convert Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      convert_images_scale: number;
      /**
       * Convert Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      convert_md_page_break_placeholder: string;
      /**
       * Convert Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_code_enrichment: boolean;
      /**
       * Convert Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_formula_enrichment: boolean;
      /**
       * Convert Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_classification: boolean;
      /**
       * Convert Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_description: boolean;
      /**
       * Convert Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      convert_picture_description_area_threshold: number;
      /**
       * Convert Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      convert_picture_description_local?: string;
      /**
       * Convert Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      convert_picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      convert_vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Convert Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      convert_vlm_pipeline_model_local?: string;
      /**
       * Convert Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      convert_vlm_pipeline_model_api?: string;
      /**
       * Chunking Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      chunking_use_markdown_tables: boolean;
      /**
       * Chunking Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      chunking_include_raw_text: boolean;
      /**
       * Chunking Max Tokens
       * @description Maximum number of tokens per chunk. When left to none, the value is automatically extracted from the tokenizer.
       */
      chunking_max_tokens?: number | null;
      /**
       * Chunking Tokenizer
       * @description HuggingFace model name for custom tokenization. If not specified, uses 'sentence-transformers/all-MiniLM-L6-v2' as default.
       * @default sentence-transformers/all-MiniLM-L6-v2
       * @example Qwen/Qwen3-Embedding-0.6B
       * @example sentence-transformers/all-MiniLM-L6-v2
       */
      chunking_tokenizer: string;
      /**
       * Chunking Merge Peers
       * @description Merge undersized successive chunks with same headings.
       * @default true
       */
      chunking_merge_peers: boolean;
    };
    /** Body_Chunk_files_with_HierarchicalChunker_v1_chunk_hierarchical_file_post */
    Body_Chunk_files_with_HierarchicalChunker_v1_chunk_hierarchical_file_post: {
      /** Files */
      files: string[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * @description Specification for the type of output target.
       * @default inbody
       */
      target_type: components["schemas"]["TargetName"];
      /**
       * Convert From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      convert_from_formats: components["schemas"]["InputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      convert_image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Convert Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      convert_do_ocr: boolean;
      /**
       * Convert Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      convert_ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Convert Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      convert_ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      convert_pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      convert_table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Convert Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      convert_table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      convert_pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Convert Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      convert_page_range: [number, number];
      /**
       * Convert Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      convert_document_timeout: number;
      /**
       * Convert Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_abort_on_error: boolean;
      /**
       * Convert Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_do_table_structure: boolean;
      /**
       * Convert Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_include_images: boolean;
      /**
       * Convert Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      convert_images_scale: number;
      /**
       * Convert Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      convert_md_page_break_placeholder: string;
      /**
       * Convert Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_code_enrichment: boolean;
      /**
       * Convert Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_formula_enrichment: boolean;
      /**
       * Convert Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_classification: boolean;
      /**
       * Convert Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_description: boolean;
      /**
       * Convert Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      convert_picture_description_area_threshold: number;
      /**
       * Convert Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      convert_picture_description_local?: string;
      /**
       * Convert Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      convert_picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      convert_vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Convert Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      convert_vlm_pipeline_model_local?: string;
      /**
       * Convert Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      convert_vlm_pipeline_model_api?: string;
      /**
       * Chunking Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      chunking_use_markdown_tables: boolean;
      /**
       * Chunking Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      chunking_include_raw_text: boolean;
      /**
       * Chunking Max Tokens
       * @description Maximum number of tokens per chunk. When left to none, the value is automatically extracted from the tokenizer.
       */
      chunking_max_tokens?: number | null;
      /**
       * Chunking Tokenizer
       * @description HuggingFace model name for custom tokenization. If not specified, uses 'sentence-transformers/all-MiniLM-L6-v2' as default.
       * @default sentence-transformers/all-MiniLM-L6-v2
       * @example Qwen/Qwen3-Embedding-0.6B
       * @example sentence-transformers/all-MiniLM-L6-v2
       */
      chunking_tokenizer: string;
      /**
       * Chunking Merge Peers
       * @description Merge undersized successive chunks with same headings.
       * @default true
       */
      chunking_merge_peers: boolean;
    };
    /** Body_Chunk_files_with_HybridChunker_as_async_task_v1_chunk_hybrid_file_async_post */
    Body_Chunk_files_with_HybridChunker_as_async_task_v1_chunk_hybrid_file_async_post: {
      /** Files */
      files: string[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * @description Specification for the type of output target.
       * @default inbody
       */
      target_type: components["schemas"]["TargetName"];
      /**
       * Convert From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      convert_from_formats: components["schemas"]["InputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      convert_image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Convert Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      convert_do_ocr: boolean;
      /**
       * Convert Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      convert_ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Convert Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      convert_ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      convert_pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      convert_table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Convert Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      convert_table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      convert_pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Convert Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      convert_page_range: [number, number];
      /**
       * Convert Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      convert_document_timeout: number;
      /**
       * Convert Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_abort_on_error: boolean;
      /**
       * Convert Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_do_table_structure: boolean;
      /**
       * Convert Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_include_images: boolean;
      /**
       * Convert Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      convert_images_scale: number;
      /**
       * Convert Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      convert_md_page_break_placeholder: string;
      /**
       * Convert Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_code_enrichment: boolean;
      /**
       * Convert Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_formula_enrichment: boolean;
      /**
       * Convert Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_classification: boolean;
      /**
       * Convert Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_description: boolean;
      /**
       * Convert Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      convert_picture_description_area_threshold: number;
      /**
       * Convert Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      convert_picture_description_local?: string;
      /**
       * Convert Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      convert_picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      convert_vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Convert Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      convert_vlm_pipeline_model_local?: string;
      /**
       * Convert Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      convert_vlm_pipeline_model_api?: string;
      /**
       * Chunking Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      chunking_use_markdown_tables: boolean;
      /**
       * Chunking Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      chunking_include_raw_text: boolean;
      /**
       * Chunking Max Tokens
       * @description Maximum number of tokens per chunk. When left to none, the value is automatically extracted from the tokenizer.
       */
      chunking_max_tokens?: number | null;
      /**
       * Chunking Tokenizer
       * @description HuggingFace model name for custom tokenization. If not specified, uses 'sentence-transformers/all-MiniLM-L6-v2' as default.
       * @default sentence-transformers/all-MiniLM-L6-v2
       * @example Qwen/Qwen3-Embedding-0.6B
       * @example sentence-transformers/all-MiniLM-L6-v2
       */
      chunking_tokenizer: string;
      /**
       * Chunking Merge Peers
       * @description Merge undersized successive chunks with same headings.
       * @default true
       */
      chunking_merge_peers: boolean;
    };
    /** Body_Chunk_files_with_HybridChunker_v1_chunk_hybrid_file_post */
    Body_Chunk_files_with_HybridChunker_v1_chunk_hybrid_file_post: {
      /** Files */
      files: string[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * @description Specification for the type of output target.
       * @default inbody
       */
      target_type: components["schemas"]["TargetName"];
      /**
       * Convert From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      convert_from_formats: components["schemas"]["InputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      convert_image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Convert Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      convert_do_ocr: boolean;
      /**
       * Convert Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      convert_ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Convert Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      convert_ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      convert_pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      convert_table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Convert Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      convert_table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      convert_pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Convert Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      convert_page_range: [number, number];
      /**
       * Convert Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      convert_document_timeout: number;
      /**
       * Convert Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      convert_abort_on_error: boolean;
      /**
       * Convert Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_do_table_structure: boolean;
      /**
       * Convert Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      convert_include_images: boolean;
      /**
       * Convert Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      convert_images_scale: number;
      /**
       * Convert Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      convert_md_page_break_placeholder: string;
      /**
       * Convert Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_code_enrichment: boolean;
      /**
       * Convert Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_formula_enrichment: boolean;
      /**
       * Convert Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_classification: boolean;
      /**
       * Convert Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      convert_do_picture_description: boolean;
      /**
       * Convert Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      convert_picture_description_area_threshold: number;
      /**
       * Convert Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      convert_picture_description_local?: string;
      /**
       * Convert Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      convert_picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      convert_vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Convert Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      convert_vlm_pipeline_model_local?: string;
      /**
       * Convert Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      convert_vlm_pipeline_model_api?: string;
      /**
       * Chunking Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      chunking_use_markdown_tables: boolean;
      /**
       * Chunking Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      chunking_include_raw_text: boolean;
      /**
       * Chunking Max Tokens
       * @description Maximum number of tokens per chunk. When left to none, the value is automatically extracted from the tokenizer.
       */
      chunking_max_tokens?: number | null;
      /**
       * Chunking Tokenizer
       * @description HuggingFace model name for custom tokenization. If not specified, uses 'sentence-transformers/all-MiniLM-L6-v2' as default.
       * @default sentence-transformers/all-MiniLM-L6-v2
       * @example Qwen/Qwen3-Embedding-0.6B
       * @example sentence-transformers/all-MiniLM-L6-v2
       */
      chunking_tokenizer: string;
      /**
       * Chunking Merge Peers
       * @description Merge undersized successive chunks with same headings.
       * @default true
       */
      chunking_merge_peers: boolean;
    };
    /** Body_process_file_async_v1_convert_file_async_post */
    Body_process_file_async_v1_convert_file_async_post: {
      /** Files */
      files: string[];
      /** @default inbody */
      target_type: components["schemas"]["TargetName"];
      /**
       * From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      from_formats: components["schemas"]["InputFormat"][];
      /**
       * To Formats
       * @description Output format(s) to convert to. String or list of strings. Allowed values: md, json, html, html_split_page, text, doctags. Optional, defaults to Markdown.
       * @default [
       *       "md"
       *     ]
       * @example [
       *       "md"
       *     ]
       * @example [
       *       "md",
       *       "json"
       *     ]
       * @example [
       *       "md",
       *       "json",
       *       "html",
       *       "html_split_page",
       *       "text",
       *       "doctags"
       *     ]
       */
      to_formats: components["schemas"]["OutputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      do_ocr: boolean;
      /**
       * Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      page_range: [number, number];
      /**
       * Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      document_timeout: number;
      /**
       * Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      abort_on_error: boolean;
      /**
       * Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      do_table_structure: boolean;
      /**
       * Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      include_images: boolean;
      /**
       * Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      images_scale: number;
      /**
       * Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      md_page_break_placeholder: string;
      /**
       * Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_code_enrichment: boolean;
      /**
       * Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_formula_enrichment: boolean;
      /**
       * Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_classification: boolean;
      /**
       * Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_description: boolean;
      /**
       * Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      picture_description_area_threshold: number;
      /**
       * Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      picture_description_local?: string;
      /**
       * Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      vlm_pipeline_model_local?: string;
      /**
       * Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      vlm_pipeline_model_api?: string;
    };
    /** Body_process_file_v1_convert_file_post */
    Body_process_file_v1_convert_file_post: {
      /** Files */
      files: string[];
      /** @default inbody */
      target_type: components["schemas"]["TargetName"];
      /**
       * From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      from_formats: components["schemas"]["InputFormat"][];
      /**
       * To Formats
       * @description Output format(s) to convert to. String or list of strings. Allowed values: md, json, html, html_split_page, text, doctags. Optional, defaults to Markdown.
       * @default [
       *       "md"
       *     ]
       * @example [
       *       "md"
       *     ]
       * @example [
       *       "md",
       *       "json"
       *     ]
       * @example [
       *       "md",
       *       "json",
       *       "html",
       *       "html_split_page",
       *       "text",
       *       "doctags"
       *     ]
       */
      to_formats: components["schemas"]["OutputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      do_ocr: boolean;
      /**
       * Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      page_range: [number, number];
      /**
       * Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      document_timeout: number;
      /**
       * Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      abort_on_error: boolean;
      /**
       * Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      do_table_structure: boolean;
      /**
       * Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      include_images: boolean;
      /**
       * Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      images_scale: number;
      /**
       * Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      md_page_break_placeholder: string;
      /**
       * Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_code_enrichment: boolean;
      /**
       * Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_formula_enrichment: boolean;
      /**
       * Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_classification: boolean;
      /**
       * Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_description: boolean;
      /**
       * Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      picture_description_area_threshold: number;
      /**
       * Picture Description Local
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       * @example {"repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct", "prompt": "Describe this image in a few sentences.", "generation_config": {"max_new_tokens": 200, "do_sample": false}}
       */
      picture_description_local?: string;
      /**
       * Picture Description Api
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       * @example {"url": "http://localhost:11434/v1/chat/completions", "headers": {}, "params": {"model": "granite3.2-vision:2b"}, "timeout": 20.0, "concurrency": 1, "prompt": "Describe this image in a few sentences."}
       */
      picture_description_api?: string;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * Vlm Pipeline Model Local
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "transformers", "transformers_model_type": "automodel-imagetexttotext", "extra_generation_config": {}}
       * @example {"repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16", "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags", "inference_framework": "mlx", "transformers_model_type": "automodel", "extra_generation_config": {}}
       * @example {"repo_id": "ibm-granite/granite-vision-3.2-2b", "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!", "scale": 2.0, "response_format": "markdown", "inference_framework": "transformers", "transformers_model_type": "automodel-vision2seq", "extra_generation_config": {}}
       */
      vlm_pipeline_model_local?: string;
      /**
       * Vlm Pipeline Model Api
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {"url": "http://localhost:1234/v1/chat/completions", "headers": {}, "params": {"model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"}, "timeout": 60.0, "concurrency": 1, "prompt": "Convert this page to docling.", "scale": 2.0, "response_format": "doctags"}
       */
      vlm_pipeline_model_api?: string;
    };
    /**
     * BoundingBox
     * @description BoundingBox.
     */
    BoundingBox: {
      /** L */
      l: number;
      /** T */
      t: number;
      /** R */
      r: number;
      /** B */
      b: number;
      /** @default TOPLEFT */
      coord_origin: components["schemas"]["CoordOrigin"];
    };
    /**
     * ChartBar
     * @description Represents a bar in a bar chart.
     *
     *     Attributes:
     *         label (str): The label for the bar.
     *         values (float): The value associated with the bar.
     */
    ChartBar: {
      /** Label */
      label: string;
      /** Values */
      values: number;
    };
    /**
     * ChartLine
     * @description Represents a line in a line chart.
     *
     *     Attributes:
     *         label (str): The label for the line.
     *         values (List[Tuple[float, float]]): A list of (x, y) coordinate pairs
     *             representing the line's data points.
     */
    ChartLine: {
      /** Label */
      label: string;
      /** Values */
      values: [number, number][];
    };
    /**
     * ChartPoint
     * @description Represents a point in a scatter chart.
     *
     *     Attributes:
     *         value (Tuple[float, float]): A (x, y) coordinate pair representing a point in a
     *             chart.
     */
    ChartPoint: {
      /** Value */
      value: [number, number];
    };
    /**
     * ChartSlice
     * @description Represents a slice in a pie chart.
     *
     *     Attributes:
     *         label (str): The label for the slice.
     *         value (float): The value represented by the slice.
     */
    ChartSlice: {
      /** Label */
      label: string;
      /** Value */
      value: number;
    };
    /**
     * ChartStackedBar
     * @description Represents a stacked bar in a stacked bar chart.
     *
     *     Attributes:
     *         label (List[str]): The labels for the stacked bars. Multiple values are stored
     *             in cases where the chart is "double stacked," meaning bars are stacked both
     *             horizontally and vertically.
     *         values (List[Tuple[str, int]]): A list of values representing different segments
     *             of the stacked bar along with their label.
     */
    ChartStackedBar: {
      /** Label */
      label: string[];
      /** Values */
      values: [string, number][];
    };
    /** ChunkDocumentResponse */
    ChunkDocumentResponse: {
      /** Chunks */
      chunks: components["schemas"]["ChunkedDocumentResultItem"][];
      /** Documents */
      documents: components["schemas"]["ExportResult"][];
      /** Processing Time */
      processing_time: number;
    };
    /**
     * ChunkedDocumentResultItem
     * @description A single chunk of a document with its metadata and content.
     */
    ChunkedDocumentResultItem: {
      /** Filename */
      filename: string;
      /** Chunk Index */
      chunk_index: number;
      /**
       * Text
       * @description The chunk text with structural context (headers, formatting)
       */
      text: string;
      /**
       * Raw Text
       * @description Raw chunk text without additional formatting or context
       */
      raw_text?: string | null;
      /**
       * Num Tokens
       * @description Number of tokens in the text, if the chunker is aware of tokens
       */
      num_tokens?: number | null;
      /**
       * Headings
       * @description List of headings for this chunk
       */
      headings?: string[] | null;
      /**
       * Captions
       * @description List of captions for this chunk (e.g. for pictures and tables)
       */
      captions?: string[] | null;
      /**
       * Doc Items
       * @description List of doc items references
       */
      doc_items: string[];
      /**
       * Page Numbers
       * @description Page numbers where this chunk content appears
       */
      page_numbers?: number[] | null;
      /**
       * Metadata
       * @description Additional metadata associated with this chunk
       */
      metadata?: Record<string, never> | null;
    };
    /** ClearResponse */
    ClearResponse: {
      /**
       * Status
       * @default ok
       */
      status: string;
    };
    /**
     * CodeItem
     * @description CodeItem.
     */
    CodeItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default code
       * @constant
       */
      label: "code";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
      /**
       * Captions
       * @default []
       */
      captions: components["schemas"]["RefItem"][];
      /**
       * References
       * @default []
       */
      references: components["schemas"]["RefItem"][];
      /**
       * Footnotes
       * @default []
       */
      footnotes: components["schemas"]["RefItem"][];
      image?: components["schemas"]["ImageRef"] | null;
      /** @default unknown */
      code_language: components["schemas"]["CodeLanguageLabel"];
    };
    /**
     * CodeLanguageLabel
     * @description CodeLanguageLabel.
     * @enum {string}
     */
    CodeLanguageLabel:
      | "Ada"
      | "Awk"
      | "Bash"
      | "bc"
      | "C"
      | "C#"
      | "C++"
      | "CMake"
      | "COBOL"
      | "CSS"
      | "Ceylon"
      | "Clojure"
      | "Crystal"
      | "Cuda"
      | "Cython"
      | "D"
      | "Dart"
      | "dc"
      | "Dockerfile"
      | "Elixir"
      | "Erlang"
      | "FORTRAN"
      | "Forth"
      | "Go"
      | "HTML"
      | "Haskell"
      | "Haxe"
      | "Java"
      | "JavaScript"
      | "Julia"
      | "Kotlin"
      | "Lisp"
      | "Lua"
      | "Matlab"
      | "MoonScript"
      | "Nim"
      | "OCaml"
      | "ObjectiveC"
      | "Octave"
      | "PHP"
      | "Pascal"
      | "Perl"
      | "Prolog"
      | "Python"
      | "Racket"
      | "Ruby"
      | "Rust"
      | "SML"
      | "SQL"
      | "Scala"
      | "Scheme"
      | "Swift"
      | "TypeScript"
      | "unknown"
      | "VisualBasic"
      | "XML"
      | "YAML";
    /**
     * ContentLayer
     * @description ContentLayer.
     * @enum {string}
     */
    ContentLayer: "body" | "furniture" | "background" | "invisible" | "notes";
    /**
     * ConversionStatus
     * @enum {string}
     */
    ConversionStatus:
      | "pending"
      | "started"
      | "failure"
      | "success"
      | "partial_success"
      | "skipped";
    /** ConvertDocumentResponse */
    ConvertDocumentResponse: {
      document: components["schemas"]["ExportDocumentResponse"];
      status: components["schemas"]["ConversionStatus"];
      /**
       * Errors
       * @default []
       */
      errors: components["schemas"]["ErrorItem"][];
      /** Processing Time */
      processing_time: number;
      /**
       * Timings
       * @default {}
       */
      timings: {
        [key: string]: components["schemas"]["ProfilingItem"];
      };
    };
    /** ConvertDocumentsRequest */
    ConvertDocumentsRequest: {
      /** @default {
       *       "from_formats": [
       *         "docx",
       *         "pptx",
       *         "html",
       *         "image",
       *         "pdf",
       *         "asciidoc",
       *         "md",
       *         "csv",
       *         "xlsx",
       *         "xml_uspto",
       *         "xml_jats",
       *         "mets_gbs",
       *         "json_docling",
       *         "audio"
       *       ],
       *       "to_formats": [
       *         "md"
       *       ],
       *       "image_export_mode": "embedded",
       *       "do_ocr": true,
       *       "force_ocr": false,
       *       "ocr_engine": "easyocr",
       *       "pdf_backend": "dlparse_v4",
       *       "table_mode": "accurate",
       *       "table_cell_matching": true,
       *       "pipeline": "standard",
       *       "page_range": [
       *         1,
       *         9223372036854776000
       *       ],
       *       "document_timeout": 604800,
       *       "abort_on_error": false,
       *       "do_table_structure": true,
       *       "include_images": true,
       *       "images_scale": 2,
       *       "md_page_break_placeholder": "",
       *       "do_code_enrichment": false,
       *       "do_formula_enrichment": false,
       *       "do_picture_classification": false,
       *       "do_picture_description": false,
       *       "picture_description_area_threshold": 0.05
       *     } */
      options: components["schemas"]["ConvertDocumentsRequestOptions"];
      /** Sources */
      sources: (
        | components["schemas"]["FileSourceRequest"]
        | components["schemas"]["HttpSourceRequest"]
        | components["schemas"]["S3SourceRequest"]
      )[];
      /**
       * Target
       * @default {
       *       "kind": "inbody"
       *     }
       */
      target:
        | components["schemas"]["InBodyTarget"]
        | components["schemas"]["ZipTarget"]
        | components["schemas"]["S3Target"]
        | components["schemas"]["PutTarget"];
    };
    /** ConvertDocumentsRequestOptions */
    ConvertDocumentsRequestOptions: {
      /**
       * From Formats
       * @description Input format(s) to convert from. String or list of strings. Allowed values: docx, pptx, html, image, pdf, asciidoc, md, csv, xlsx, xml_uspto, xml_jats, mets_gbs, json_docling, audio. Optional, defaults to all formats.
       * @default [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       * @example [
       *       "docx",
       *       "pptx",
       *       "html",
       *       "image",
       *       "pdf",
       *       "asciidoc",
       *       "md",
       *       "csv",
       *       "xlsx",
       *       "xml_uspto",
       *       "xml_jats",
       *       "mets_gbs",
       *       "json_docling",
       *       "audio"
       *     ]
       */
      from_formats: components["schemas"]["InputFormat"][];
      /**
       * To Formats
       * @description Output format(s) to convert to. String or list of strings. Allowed values: md, json, html, html_split_page, text, doctags. Optional, defaults to Markdown.
       * @default [
       *       "md"
       *     ]
       * @example [
       *       "md"
       *     ]
       * @example [
       *       "md",
       *       "json"
       *     ]
       * @example [
       *       "md",
       *       "json",
       *       "html",
       *       "html_split_page",
       *       "text",
       *       "doctags"
       *     ]
       */
      to_formats: components["schemas"]["OutputFormat"][];
      /**
       * @description Image export mode for the document (in case of JSON, Markdown or HTML). Allowed values: placeholder, embedded, referenced. Optional, defaults to Embedded.
       * @default embedded
       * @example embedded
       */
      image_export_mode: components["schemas"]["ImageRefMode"];
      /**
       * Do Ocr
       * @description If enabled, the bitmap content will be processed using OCR. Boolean. Optional, defaults to true
       * @default true
       */
      do_ocr: boolean;
      /**
       * Force Ocr
       * @description If enabled, replace existing text with OCR-generated text over content. Boolean. Optional, defaults to false.
       * @default false
       */
      force_ocr: boolean;
      /**
       * @description The OCR engine to use. String. Allowed values: easyocr, ocrmac, rapidocr, tesserocr, tesseract. Optional, defaults to easyocr.
       * @default easyocr
       * @example easyocr
       */
      ocr_engine: components["schemas"]["ocr_engines_enum"];
      /**
       * Ocr Lang
       * @description List of languages used by the OCR engine. Note that each OCR engine has different values for the language names. String or list of strings. Optional, defaults to empty.
       * @example [
       *       "fr",
       *       "de",
       *       "es",
       *       "en"
       *     ]
       */
      ocr_lang?: string[] | null;
      /**
       * @description The PDF backend to use. String. Allowed values: pypdfium2, dlparse_v1, dlparse_v2, dlparse_v4. Optional, defaults to dlparse_v4.
       * @default dlparse_v4
       * @example dlparse_v4
       */
      pdf_backend: components["schemas"]["PdfBackend"];
      /**
       * @description Mode to use for table structure, String. Allowed values: fast, accurate. Optional, defaults to fast.
       * @default accurate
       * @example accurate
       */
      table_mode: components["schemas"]["TableFormerMode"];
      /**
       * Table Cell Matching
       * @description If true, matches table cells predictions back to PDF cells. Can break table output if PDF cells are merged across table columns. If false, let table structure model define the text cells, ignore PDF cells.
       * @default true
       * @example true
       */
      table_cell_matching: boolean;
      /**
       * @description Choose the pipeline to process PDF or image files.
       * @default standard
       */
      pipeline: components["schemas"]["ProcessingPipeline"];
      /**
       * Page Range
       * @description Only convert a range of pages. The page number starts at 1.
       * @default [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       9223372036854776000
       *     ]
       * @example [
       *       1,
       *       4
       *     ]
       */
      page_range: unknown;
      /**
       * Document Timeout
       * @description The timeout for processing each document, in seconds.
       * @default 604800
       */
      document_timeout: number;
      /**
       * Abort On Error
       * @description Abort on error if enabled. Boolean. Optional, defaults to false.
       * @default false
       */
      abort_on_error: boolean;
      /**
       * Do Table Structure
       * @description If enabled, the table structure will be extracted. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      do_table_structure: boolean;
      /**
       * Include Images
       * @description If enabled, images will be extracted from the document. Boolean. Optional, defaults to true.
       * @default true
       * @example true
       */
      include_images: boolean;
      /**
       * Images Scale
       * @description Scale factor for images. Float. Optional, defaults to 2.0.
       * @default 2
       * @example 2
       */
      images_scale: number;
      /**
       * Md Page Break Placeholder
       * @description Add this placeholder betweek pages in the markdown output.
       * @default
       * @example <!-- page-break -->
       * @example
       */
      md_page_break_placeholder: string;
      /**
       * Do Code Enrichment
       * @description If enabled, perform OCR code enrichment. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_code_enrichment: boolean;
      /**
       * Do Formula Enrichment
       * @description If enabled, perform formula OCR, return LaTeX code. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_formula_enrichment: boolean;
      /**
       * Do Picture Classification
       * @description If enabled, classify pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_classification: boolean;
      /**
       * Do Picture Description
       * @description If enabled, describe pictures in documents. Boolean. Optional, defaults to false.
       * @default false
       * @example false
       */
      do_picture_description: boolean;
      /**
       * Picture Description Area Threshold
       * @description Minimum percentage of the area for a picture to be processed with the models.
       * @default 0.05
       * @example 0.05
       */
      picture_description_area_threshold: number;
      /**
       * @description Options for running a local vision-language model in the picture description. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with picture_description_api.
       * @example {
       *       "generation_config": {
       *         "do_sample": false,
       *         "max_new_tokens": 200
       *       },
       *       "prompt": "Describe this image in a few sentences.",
       *       "repo_id": "ibm-granite/granite-vision-3.2-2b"
       *     }
       * @example {
       *       "generation_config": {
       *         "do_sample": false,
       *         "max_new_tokens": 200
       *       },
       *       "prompt": "Describe this image in a few sentences.",
       *       "repo_id": "HuggingFaceTB/SmolVLM-256M-Instruct"
       *     }
       */
      picture_description_local?:
        | components["schemas"]["PictureDescriptionLocal"]
        | null;
      /**
       * @description API details for using a vision-language model in the picture description. This parameter is mutually exclusive with picture_description_local.
       * @example {
       *       "concurrency": 1,
       *       "headers": {},
       *       "params": {
       *         "model": "granite3.2-vision:2b"
       *       },
       *       "prompt": "Describe this image in a few sentences.",
       *       "timeout": 20,
       *       "url": "http://localhost:1234/v1/chat/completions"
       *     }
       * @example {
       *       "concurrency": 1,
       *       "headers": {},
       *       "params": {
       *         "model": "granite3.2-vision:2b"
       *       },
       *       "prompt": "Describe this image in a few sentences.",
       *       "timeout": 20,
       *       "url": "http://localhost:11434/v1/chat/completions"
       *     }
       */
      picture_description_api?:
        | components["schemas"]["PictureDescriptionApi"]
        | null;
      /**
       * @description Preset of local and API models for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model_api. Use the other options for more parameters.
       * @example smoldocling
       */
      vlm_pipeline_model?: components["schemas"]["VlmModelType"] | null;
      /**
       * @description Options for running a local vision-language model for the vlm pipeline. The parameters refer to a model hosted on Hugging Face. This parameter is mutually exclusive with vlm_pipeline_model_api and vlm_pipeline_model.
       * @example {
       *       "extra_generation_config": {},
       *       "inference_framework": "transformers",
       *       "prompt": "Convert this page to docling.",
       *       "repo_id": "ds4sd/SmolDocling-256M-preview",
       *       "response_format": "doctags",
       *       "scale": 2,
       *       "transformers_model_type": "automodel-imagetexttotext"
       *     }
       * @example {
       *       "extra_generation_config": {},
       *       "inference_framework": "mlx",
       *       "prompt": "Convert this page to docling.",
       *       "repo_id": "ds4sd/SmolDocling-256M-preview-mlx-bf16",
       *       "response_format": "doctags",
       *       "scale": 2,
       *       "transformers_model_type": "automodel"
       *     }
       * @example {
       *       "extra_generation_config": {},
       *       "inference_framework": "transformers",
       *       "prompt": "Convert this page to markdown. Do not miss any text and only output the bare markdown!",
       *       "repo_id": "ibm-granite/granite-vision-3.2-2b",
       *       "response_format": "markdown",
       *       "scale": 2,
       *       "transformers_model_type": "automodel-vision2seq"
       *     }
       */
      vlm_pipeline_model_local?: components["schemas"]["VlmModelLocal"] | null;
      /**
       * @description API details for using a vision-language model for the vlm pipeline. This parameter is mutually exclusive with vlm_pipeline_model_local and vlm_pipeline_model.
       * @example {
       *       "concurrency": 1,
       *       "headers": {},
       *       "params": {
       *         "model": "ds4sd/SmolDocling-256M-preview-mlx-bf16"
       *       },
       *       "prompt": "Convert this page to docling.",
       *       "response_format": "doctags",
       *       "scale": 2,
       *       "timeout": 60,
       *       "url": "http://localhost:1234/v1/chat/completions"
       *     }
       */
      vlm_pipeline_model_api?: components["schemas"]["VlmModelApi"] | null;
    };
    /**
     * CoordOrigin
     * @description CoordOrigin.
     * @enum {string}
     */
    CoordOrigin: "TOPLEFT" | "BOTTOMLEFT";
    /**
     * DescriptionAnnotation
     * @description DescriptionAnnotation.
     */
    DescriptionAnnotation: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "description";
      /** Text */
      text: string;
      /** Provenance */
      provenance: string;
    };
    /**
     * DoclingComponentType
     * @enum {string}
     */
    DoclingComponentType:
      | "document_backend"
      | "model"
      | "doc_assembler"
      | "user_input";
    /**
     * DoclingDocument
     * @description DoclingDocument.
     */
    DoclingDocument: {
      /**
       * Schema Name
       * @default DoclingDocument
       * @constant
       */
      schema_name: "DoclingDocument";
      /**
       * Version
       * @default 1.6.0
       */
      version: string;
      /** Name */
      name: string;
      origin?: components["schemas"]["DocumentOrigin"] | null;
      /**
       * @deprecated
       * @default {
       *       "self_ref": "#/furniture",
       *       "children": [],
       *       "content_layer": "furniture",
       *       "name": "_root_",
       *       "label": "unspecified"
       *     }
       */
      furniture: components["schemas"]["GroupItem"];
      /** @default {
       *       "self_ref": "#/body",
       *       "children": [],
       *       "content_layer": "body",
       *       "name": "_root_",
       *       "label": "unspecified"
       *     } */
      body: components["schemas"]["GroupItem"];
      /**
       * Groups
       * @default []
       */
      groups: (
        | components["schemas"]["ListGroup"]
        | components["schemas"]["InlineGroup"]
        | components["schemas"]["GroupItem"]
      )[];
      /**
       * Texts
       * @default []
       */
      texts: (
        | components["schemas"]["TitleItem"]
        | components["schemas"]["SectionHeaderItem"]
        | components["schemas"]["ListItem"]
        | components["schemas"]["CodeItem"]
        | components["schemas"]["FormulaItem"]
        | components["schemas"]["TextItem"]
      )[];
      /**
       * Pictures
       * @default []
       */
      pictures: components["schemas"]["PictureItem"][];
      /**
       * Tables
       * @default []
       */
      tables: components["schemas"]["TableItem"][];
      /**
       * Key Value Items
       * @default []
       */
      key_value_items: components["schemas"]["KeyValueItem"][];
      /**
       * Form Items
       * @default []
       */
      form_items: components["schemas"]["FormItem"][];
      /**
       * Pages
       * @default {}
       */
      pages: {
        [key: string]: components["schemas"]["PageItem"];
      };
    };
    /**
     * DocumentOrigin
     * @description FileSource.
     */
    DocumentOrigin: {
      /** Mimetype */
      mimetype: string;
      /** Binary Hash */
      binary_hash: number;
      /** Filename */
      filename: string;
      /** Uri */
      uri?: string | null;
    };
    /** ErrorItem */
    ErrorItem: {
      component_type: components["schemas"]["DoclingComponentType"];
      /** Module Name */
      module_name: string;
      /** Error Message */
      error_message: string;
    };
    /** ExportDocumentResponse */
    ExportDocumentResponse: {
      /** Filename */
      filename: string;
      /** Md Content */
      md_content?: string | null;
      json_content?: components["schemas"]["DoclingDocument"] | null;
      /** Html Content */
      html_content?: string | null;
      /** Text Content */
      text_content?: string | null;
      /** Doctags Content */
      doctags_content?: string | null;
    };
    /**
     * ExportResult
     * @description Container of all exported content.
     */
    ExportResult: {
      /**
       * Kind
       * @default ExportResult
       * @constant
       */
      kind: "ExportResult";
      content: components["schemas"]["ExportDocumentResponse"];
      status: components["schemas"]["ConversionStatus"];
      /**
       * Errors
       * @default []
       */
      errors: components["schemas"]["ErrorItem"][];
      /**
       * Timings
       * @default {}
       */
      timings: {
        [key: string]: components["schemas"]["ProfilingItem"];
      };
    };
    /** FileSourceRequest */
    FileSourceRequest: {
      /**
       * Base64 String
       * @description Content of the file serialized in base64. For example it can be obtained via `base64 -w 0 /path/to/file/pdf-to-convert.pdf`.
       */
      base64_string: string;
      /**
       * Filename
       * @description Filename of the uploaded document
       * @example file.pdf
       */
      filename: string;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "file";
    };
    /**
     * FormItem
     * @description FormItem.
     */
    FormItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default form
       * @constant
       */
      label: "form";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /**
       * Captions
       * @default []
       */
      captions: components["schemas"]["RefItem"][];
      /**
       * References
       * @default []
       */
      references: components["schemas"]["RefItem"][];
      /**
       * Footnotes
       * @default []
       */
      footnotes: components["schemas"]["RefItem"][];
      image?: components["schemas"]["ImageRef"] | null;
      graph: components["schemas"]["GraphData"];
    };
    /**
     * Formatting
     * @description Formatting.
     */
    Formatting: {
      /**
       * Bold
       * @default false
       */
      bold: boolean;
      /**
       * Italic
       * @default false
       */
      italic: boolean;
      /**
       * Underline
       * @default false
       */
      underline: boolean;
      /**
       * Strikethrough
       * @default false
       */
      strikethrough: boolean;
      /** @default baseline */
      script: components["schemas"]["Script"];
    };
    /**
     * FormulaItem
     * @description FormulaItem.
     */
    FormulaItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default formula
       * @constant
       */
      label: "formula";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
    };
    /**
     * GraphCell
     * @description GraphCell.
     */
    GraphCell: {
      label: components["schemas"]["GraphCellLabel"];
      /** Cell Id */
      cell_id: number;
      /** Text */
      text: string;
      /** Orig */
      orig: string;
      prov?: components["schemas"]["ProvenanceItem"] | null;
      item_ref?: components["schemas"]["RefItem"] | null;
    };
    /**
     * GraphCellLabel
     * @description GraphCellLabel.
     * @enum {string}
     */
    GraphCellLabel: "unspecified" | "key" | "value" | "checkbox";
    /**
     * GraphData
     * @description GraphData.
     */
    GraphData: {
      /** Cells */
      cells?: components["schemas"]["GraphCell"][];
      /** Links */
      links?: components["schemas"]["GraphLink"][];
    };
    /**
     * GraphLink
     * @description GraphLink.
     */
    GraphLink: {
      label: components["schemas"]["GraphLinkLabel"];
      /** Source Cell Id */
      source_cell_id: number;
      /** Target Cell Id */
      target_cell_id: number;
    };
    /**
     * GraphLinkLabel
     * @description GraphLinkLabel.
     * @enum {string}
     */
    GraphLinkLabel:
      | "unspecified"
      | "to_value"
      | "to_key"
      | "to_parent"
      | "to_child";
    /**
     * GroupItem
     * @description GroupItem.
     */
    GroupItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Name
       * @default group
       */
      name: string;
      /** @default unspecified */
      label: components["schemas"]["GroupLabel"];
    };
    /**
     * GroupLabel
     * @description GroupLabel.
     * @enum {string}
     */
    GroupLabel:
      | "unspecified"
      | "list"
      | "ordered_list"
      | "chapter"
      | "section"
      | "sheet"
      | "slide"
      | "form_area"
      | "key_value_area"
      | "comment_section"
      | "inline"
      | "picture_area";
    /** HTTPValidationError */
    HTTPValidationError: {
      /** Detail */
      detail?: components["schemas"]["ValidationError"][];
    };
    /** HealthCheckResponse */
    HealthCheckResponse: {
      /**
       * Status
       * @default ok
       */
      status: string;
    };
    /**
     * HierarchicalChunkerOptions
     * @description Configuration options for the HierarchicalChunker.
     */
    HierarchicalChunkerOptions: {
      /**
       * Chunker
       * @default hierarchical
       * @constant
       */
      chunker: "hierarchical";
      /**
       * Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      use_markdown_tables: boolean;
      /**
       * Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      include_raw_text: boolean;
    };
    /** HierarchicalChunkerOptionsDocumentsRequest */
    HierarchicalChunkerOptionsDocumentsRequest: {
      /**
       * @description Conversion options.
       * @default {
       *       "from_formats": [
       *         "docx",
       *         "pptx",
       *         "html",
       *         "image",
       *         "pdf",
       *         "asciidoc",
       *         "md",
       *         "csv",
       *         "xlsx",
       *         "xml_uspto",
       *         "xml_jats",
       *         "mets_gbs",
       *         "json_docling",
       *         "audio"
       *       ],
       *       "to_formats": [
       *         "md"
       *       ],
       *       "image_export_mode": "embedded",
       *       "do_ocr": true,
       *       "force_ocr": false,
       *       "ocr_engine": "easyocr",
       *       "pdf_backend": "dlparse_v4",
       *       "table_mode": "accurate",
       *       "table_cell_matching": true,
       *       "pipeline": "standard",
       *       "page_range": [
       *         1,
       *         9223372036854776000
       *       ],
       *       "document_timeout": 604800,
       *       "abort_on_error": false,
       *       "do_table_structure": true,
       *       "include_images": true,
       *       "images_scale": 2,
       *       "md_page_break_placeholder": "",
       *       "do_code_enrichment": false,
       *       "do_formula_enrichment": false,
       *       "do_picture_classification": false,
       *       "do_picture_description": false,
       *       "picture_description_area_threshold": 0.05
       *     }
       */
      convert_options: components["schemas"]["ConvertDocumentsRequestOptions"];
      /**
       * Sources
       * @description List of input document sources to process.
       */
      sources: (
        | components["schemas"]["FileSourceRequest"]
        | components["schemas"]["HttpSourceRequest"]
        | components["schemas"]["S3SourceRequest"]
      )[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * Target
       * @description Specification for the type of output target.
       * @default {
       *       "kind": "inbody"
       *     }
       */
      target:
        | components["schemas"]["InBodyTarget"]
        | components["schemas"]["ZipTarget"]
        | components["schemas"]["S3Target"]
        | components["schemas"]["PutTarget"];
      /** @description Options specific to the chunker. */
      chunking_options?: components["schemas"]["HierarchicalChunkerOptions"];
    };
    /** HttpSourceRequest */
    HttpSourceRequest: {
      /**
       * Url
       * Format: uri
       * @description HTTP url to process
       * @example https://arxiv.org/pdf/2206.01062
       */
      url: string;
      /**
       * Headers
       * @description Additional headers used to fetch the urls, e.g. authorization, agent, etc
       * @default {}
       */
      headers: Record<string, never>;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "http";
    };
    /**
     * HybridChunkerOptions
     * @description Configuration options for the HybridChunker.
     */
    HybridChunkerOptions: {
      /**
       * Chunker
       * @default hybrid
       * @constant
       */
      chunker: "hybrid";
      /**
       * Use Markdown Tables
       * @description Use markdown table format instead of triplets for table serialization.
       * @default false
       */
      use_markdown_tables: boolean;
      /**
       * Include Raw Text
       * @description Include both raw_text and text (contextualized) in response. If False, only text is included.
       * @default false
       */
      include_raw_text: boolean;
      /**
       * Max Tokens
       * @description Maximum number of tokens per chunk. When left to none, the value is automatically extracted from the tokenizer.
       */
      max_tokens?: number | null;
      /**
       * Tokenizer
       * @description HuggingFace model name for custom tokenization. If not specified, uses 'sentence-transformers/all-MiniLM-L6-v2' as default.
       * @default sentence-transformers/all-MiniLM-L6-v2
       * @example Qwen/Qwen3-Embedding-0.6B
       * @example sentence-transformers/all-MiniLM-L6-v2
       */
      tokenizer: string;
      /**
       * Merge Peers
       * @description Merge undersized successive chunks with same headings.
       * @default true
       */
      merge_peers: boolean;
    };
    /** HybridChunkerOptionsDocumentsRequest */
    HybridChunkerOptionsDocumentsRequest: {
      /**
       * @description Conversion options.
       * @default {
       *       "from_formats": [
       *         "docx",
       *         "pptx",
       *         "html",
       *         "image",
       *         "pdf",
       *         "asciidoc",
       *         "md",
       *         "csv",
       *         "xlsx",
       *         "xml_uspto",
       *         "xml_jats",
       *         "mets_gbs",
       *         "json_docling",
       *         "audio"
       *       ],
       *       "to_formats": [
       *         "md"
       *       ],
       *       "image_export_mode": "embedded",
       *       "do_ocr": true,
       *       "force_ocr": false,
       *       "ocr_engine": "easyocr",
       *       "pdf_backend": "dlparse_v4",
       *       "table_mode": "accurate",
       *       "table_cell_matching": true,
       *       "pipeline": "standard",
       *       "page_range": [
       *         1,
       *         9223372036854776000
       *       ],
       *       "document_timeout": 604800,
       *       "abort_on_error": false,
       *       "do_table_structure": true,
       *       "include_images": true,
       *       "images_scale": 2,
       *       "md_page_break_placeholder": "",
       *       "do_code_enrichment": false,
       *       "do_formula_enrichment": false,
       *       "do_picture_classification": false,
       *       "do_picture_description": false,
       *       "picture_description_area_threshold": 0.05
       *     }
       */
      convert_options: components["schemas"]["ConvertDocumentsRequestOptions"];
      /**
       * Sources
       * @description List of input document sources to process.
       */
      sources: (
        | components["schemas"]["FileSourceRequest"]
        | components["schemas"]["HttpSourceRequest"]
        | components["schemas"]["S3SourceRequest"]
      )[];
      /**
       * Include Converted Doc
       * @description If true, the output will include both the chunks and the converted document.
       * @default false
       */
      include_converted_doc: boolean;
      /**
       * Target
       * @description Specification for the type of output target.
       * @default {
       *       "kind": "inbody"
       *     }
       */
      target:
        | components["schemas"]["InBodyTarget"]
        | components["schemas"]["ZipTarget"]
        | components["schemas"]["S3Target"]
        | components["schemas"]["PutTarget"];
      /** @description Options specific to the chunker. */
      chunking_options?: components["schemas"]["HybridChunkerOptions"];
    };
    /**
     * ImageRef
     * @description ImageRef.
     */
    ImageRef: {
      /** Mimetype */
      mimetype: string;
      /** Dpi */
      dpi: number;
      size: components["schemas"]["Size"];
      /** Uri */
      uri: string;
    };
    /**
     * ImageRefMode
     * @description ImageRefMode.
     * @enum {string}
     */
    ImageRefMode: "placeholder" | "embedded" | "referenced";
    /** InBodyTarget */
    InBodyTarget: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "inbody";
    };
    /**
     * InferenceFramework
     * @enum {string}
     */
    InferenceFramework: "mlx" | "transformers" | "vllm";
    /**
     * InlineGroup
     * @description InlineGroup.
     */
    InlineGroup: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Name
       * @default group
       */
      name: string;
      /**
       * Label
       * @default inline
       * @constant
       */
      label: "inline";
    };
    /**
     * InputFormat
     * @description A document format supported by document backend parsers.
     * @enum {string}
     */
    InputFormat:
      | "docx"
      | "pptx"
      | "html"
      | "image"
      | "pdf"
      | "asciidoc"
      | "md"
      | "csv"
      | "xlsx"
      | "xml_uspto"
      | "xml_jats"
      | "mets_gbs"
      | "json_docling"
      | "audio";
    /**
     * KeyValueItem
     * @description KeyValueItem.
     */
    KeyValueItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default key_value_region
       * @constant
       */
      label: "key_value_region";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /**
       * Captions
       * @default []
       */
      captions: components["schemas"]["RefItem"][];
      /**
       * References
       * @default []
       */
      references: components["schemas"]["RefItem"][];
      /**
       * Footnotes
       * @default []
       */
      footnotes: components["schemas"]["RefItem"][];
      image?: components["schemas"]["ImageRef"] | null;
      graph: components["schemas"]["GraphData"];
    };
    /**
     * ListGroup
     * @description ListGroup.
     */
    ListGroup: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Name
       * @default group
       */
      name: string;
      /**
       * Label
       * @default list
       * @constant
       */
      label: "list";
    };
    /**
     * ListItem
     * @description SectionItem.
     */
    ListItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default list_item
       * @constant
       */
      label: "list_item";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
      /**
       * Enumerated
       * @default false
       */
      enumerated: boolean;
      /**
       * Marker
       * @default -
       */
      marker: string;
    };
    /**
     * MiscAnnotation
     * @description MiscAnnotation.
     */
    MiscAnnotation: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "misc";
      /** Content */
      content: Record<string, never>;
    };
    /**
     * OutputFormat
     * @enum {string}
     */
    OutputFormat:
      | "md"
      | "json"
      | "html"
      | "html_split_page"
      | "text"
      | "doctags";
    /**
     * PageItem
     * @description PageItem.
     */
    PageItem: {
      size: components["schemas"]["Size"];
      image?: components["schemas"]["ImageRef"] | null;
      /** Page No */
      page_no: number;
    };
    /**
     * PdfBackend
     * @description Enum of valid PDF backends.
     * @enum {string}
     */
    PdfBackend: "pypdfium2" | "dlparse_v1" | "dlparse_v2" | "dlparse_v4";
    /**
     * PictureBarChartData
     * @description Represents data of a bar chart.
     *
     *     Attributes:
     *         kind (Literal["bar_chart_data"]): The type of the chart.
     *         x_axis_label (str): The label for the x-axis.
     *         y_axis_label (str): The label for the y-axis.
     *         bars (List[ChartBar]): A list of bars in the chart.
     */
    PictureBarChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "bar_chart_data";
      /** Title */
      title: string;
      /** X Axis Label */
      x_axis_label: string;
      /** Y Axis Label */
      y_axis_label: string;
      /** Bars */
      bars: components["schemas"]["ChartBar"][];
    };
    /**
     * PictureClassificationClass
     * @description PictureClassificationData.
     */
    PictureClassificationClass: {
      /** Class Name */
      class_name: string;
      /** Confidence */
      confidence: number;
    };
    /**
     * PictureClassificationData
     * @description PictureClassificationData.
     */
    PictureClassificationData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "classification";
      /** Provenance */
      provenance: string;
      /** Predicted Classes */
      predicted_classes: components["schemas"]["PictureClassificationClass"][];
    };
    /** PictureDescriptionApi */
    PictureDescriptionApi: {
      /**
       * Url
       * Format: uri
       * @description Endpoint which accepts openai-api compatible requests.
       * @example http://localhost:8000/v1/chat/completions
       * @example http://localhost:1234/v1/chat/completions
       * @example http://localhost:11434/v1/chat/completions
       */
      url: string;
      /**
       * Headers
       * @description Headers used for calling the API endpoint. For example, it could include authentication headers.
       * @default {}
       */
      headers: {
        [key: string]: string;
      };
      /**
       * Params
       * @description Model parameters.
       * @default {}
       * @example {
       *       "max_completion_tokens": 200,
       *       "model": "HuggingFaceTB/SmolVLM-256M-Instruct"
       *     }
       * @example {
       *       "max_completion_tokens": 200,
       *       "model": "ibm-granite/granite-vision-3.3-2b"
       *     }
       * @example {
       *       "model": "granite3.2-vision:2b"
       *     }
       */
      params: Record<string, never>;
      /**
       * Timeout
       * @description Timeout for the API request.
       * @default 20
       */
      timeout: number;
      /**
       * Concurrency
       * @description Maximum number of concurrent requests to the API.
       * @default 1
       * @example 1
       */
      concurrency: number;
      /**
       * Prompt
       * @description Prompt used when calling the vision-language model.
       * @default Describe this image in a few sentences.
       * @example Describe this image in a few sentences.
       * @example This is a figures from a document. Provide a detailed description of it.
       */
      prompt: string;
    };
    /** PictureDescriptionLocal */
    PictureDescriptionLocal: {
      /**
       * Repo Id
       * @description Repository id from the Hugging Face Hub.
       * @example HuggingFaceTB/SmolVLM-256M-Instruct
       * @example ibm-granite/granite-vision-3.3-2b
       */
      repo_id: string;
      /**
       * Prompt
       * @description Prompt used when calling the vision-language model.
       * @default Describe this image in a few sentences.
       * @example Describe this image in a few sentences.
       * @example This is a figure from a document. Provide a detailed description of it.
       */
      prompt: string;
      /**
       * Generation Config
       * @description Config from https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig
       * @default {
       *       "max_new_tokens": 200,
       *       "do_sample": false
       *     }
       * @example {
       *       "do_sample": false,
       *       "max_new_tokens": 200
       *     }
       */
      generation_config: Record<string, never>;
    };
    /**
     * PictureItem
     * @description PictureItem.
     */
    PictureItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default picture
       * @enum {string}
       */
      label: "picture" | "chart";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /**
       * Captions
       * @default []
       */
      captions: components["schemas"]["RefItem"][];
      /**
       * References
       * @default []
       */
      references: components["schemas"]["RefItem"][];
      /**
       * Footnotes
       * @default []
       */
      footnotes: components["schemas"]["RefItem"][];
      image?: components["schemas"]["ImageRef"] | null;
      /**
       * Annotations
       * @default []
       */
      annotations: (
        | components["schemas"]["DescriptionAnnotation"]
        | components["schemas"]["MiscAnnotation"]
        | components["schemas"]["PictureClassificationData"]
        | components["schemas"]["PictureMoleculeData"]
        | components["schemas"]["PictureTabularChartData"]
        | components["schemas"]["PictureLineChartData"]
        | components["schemas"]["PictureBarChartData"]
        | components["schemas"]["PictureStackedBarChartData"]
        | components["schemas"]["PicturePieChartData"]
        | components["schemas"]["PictureScatterChartData"]
      )[];
    };
    /**
     * PictureLineChartData
     * @description Represents data of a line chart.
     *
     *     Attributes:
     *         kind (Literal["line_chart_data"]): The type of the chart.
     *         x_axis_label (str): The label for the x-axis.
     *         y_axis_label (str): The label for the y-axis.
     *         lines (List[ChartLine]): A list of lines in the chart.
     */
    PictureLineChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "line_chart_data";
      /** Title */
      title: string;
      /** X Axis Label */
      x_axis_label: string;
      /** Y Axis Label */
      y_axis_label: string;
      /** Lines */
      lines: components["schemas"]["ChartLine"][];
    };
    /**
     * PictureMoleculeData
     * @description PictureMoleculeData.
     */
    PictureMoleculeData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "molecule_data";
      /** Smi */
      smi: string;
      /** Confidence */
      confidence: number;
      /** Class Name */
      class_name: string;
      /** Segmentation */
      segmentation: [number, number][];
      /** Provenance */
      provenance: string;
    };
    /**
     * PicturePieChartData
     * @description Represents data of a pie chart.
     *
     *     Attributes:
     *         kind (Literal["pie_chart_data"]): The type of the chart.
     *         slices (List[ChartSlice]): A list of slices in the pie chart.
     */
    PicturePieChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "pie_chart_data";
      /** Title */
      title: string;
      /** Slices */
      slices: components["schemas"]["ChartSlice"][];
    };
    /**
     * PictureScatterChartData
     * @description Represents data of a scatter chart.
     *
     *     Attributes:
     *         kind (Literal["scatter_chart_data"]): The type of the chart.
     *         x_axis_label (str): The label for the x-axis.
     *         y_axis_label (str): The label for the y-axis.
     *         points (List[ChartPoint]): A list of points in the scatter chart.
     */
    PictureScatterChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "scatter_chart_data";
      /** Title */
      title: string;
      /** X Axis Label */
      x_axis_label: string;
      /** Y Axis Label */
      y_axis_label: string;
      /** Points */
      points: components["schemas"]["ChartPoint"][];
    };
    /**
     * PictureStackedBarChartData
     * @description Represents data of a stacked bar chart.
     *
     *     Attributes:
     *         kind (Literal["stacked_bar_chart_data"]): The type of the chart.
     *         x_axis_label (str): The label for the x-axis.
     *         y_axis_label (str): The label for the y-axis.
     *         stacked_bars (List[ChartStackedBar]): A list of stacked bars in the chart.
     */
    PictureStackedBarChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "stacked_bar_chart_data";
      /** Title */
      title: string;
      /** X Axis Label */
      x_axis_label: string;
      /** Y Axis Label */
      y_axis_label: string;
      /** Stacked Bars */
      stacked_bars: components["schemas"]["ChartStackedBar"][];
    };
    /**
     * PictureTabularChartData
     * @description Base class for picture chart data.
     *
     *     Attributes:
     *         title (str): The title of the chart.
     *         chart_data (TableData): Chart data in the table format.
     */
    PictureTabularChartData: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "tabular_chart_data";
      /** Title */
      title: string;
      chart_data: components["schemas"]["TableData"];
    };
    /** PresignedUrlConvertDocumentResponse */
    PresignedUrlConvertDocumentResponse: {
      /** Processing Time */
      processing_time: number;
      /** Num Converted */
      num_converted: number;
      /** Num Succeeded */
      num_succeeded: number;
      /** Num Failed */
      num_failed: number;
    };
    /**
     * ProcessingPipeline
     * @enum {string}
     */
    ProcessingPipeline: "standard" | "vlm" | "asr";
    /** ProfilingItem */
    ProfilingItem: {
      scope: components["schemas"]["ProfilingScope"];
      /**
       * Count
       * @default 0
       */
      count: number;
      /**
       * Times
       * @default []
       */
      times: number[];
      /**
       * Start Timestamps
       * @default []
       */
      start_timestamps: string[];
    };
    /**
     * ProfilingScope
     * @enum {string}
     */
    ProfilingScope: "page" | "document";
    /**
     * ProvenanceItem
     * @description ProvenanceItem.
     */
    ProvenanceItem: {
      /** Page No */
      page_no: number;
      bbox: components["schemas"]["BoundingBox"];
      /** Charspan */
      charspan: [number, number];
    };
    /** PutTarget */
    PutTarget: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "put";
      /**
       * Url
       * Format: uri
       */
      url: string;
    };
    /**
     * RefItem
     * @description RefItem.
     */
    RefItem: {
      /** $Ref */
      $ref: string;
    };
    /**
     * ResponseFormat
     * @enum {string}
     */
    ResponseFormat: "doctags" | "markdown" | "html" | "otsl" | "plaintext";
    /**
     * RichTableCell
     * @description RichTableCell.
     */
    RichTableCell: {
      bbox?: components["schemas"]["BoundingBox"] | null;
      /**
       * Row Span
       * @default 1
       */
      row_span: number;
      /**
       * Col Span
       * @default 1
       */
      col_span: number;
      /** Start Row Offset Idx */
      start_row_offset_idx: number;
      /** End Row Offset Idx */
      end_row_offset_idx: number;
      /** Start Col Offset Idx */
      start_col_offset_idx: number;
      /** End Col Offset Idx */
      end_col_offset_idx: number;
      /** Text */
      text: string;
      /**
       * Column Header
       * @default false
       */
      column_header: boolean;
      /**
       * Row Header
       * @default false
       */
      row_header: boolean;
      /**
       * Row Section
       * @default false
       */
      row_section: boolean;
      ref: components["schemas"]["RefItem"];
    };
    /** S3SourceRequest */
    S3SourceRequest: {
      /**
       * Endpoint
       * @description S3 service endpoint, without protocol. Required.
       * @example s3.eu-de.cloud-object-storage.appdomain.cloud
       * @example s3.us-east-2.amazonaws.com
       */
      endpoint: string;
      /**
       * Verify Ssl
       * @description If enabled, SSL will be used to connect to s3. Boolean. Optional, defaults to true
       * @default true
       */
      verify_ssl: boolean;
      /**
       * Access Key
       * Format: password
       * @description S3 access key. Required.
       */
      access_key: string;
      /**
       * Secret Key
       * Format: password
       * @description S3 secret key. Required.
       */
      secret_key: string;
      /**
       * Bucket
       * @description S3 bucket name. Required.
       */
      bucket: string;
      /**
       * Key Prefix
       * @description Prefix for the object keys on s3. Optional, defaults to empty.
       * @default
       */
      key_prefix: string;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "s3";
    };
    /** S3Target */
    S3Target: {
      /**
       * Endpoint
       * @description S3 service endpoint, without protocol. Required.
       * @example s3.eu-de.cloud-object-storage.appdomain.cloud
       * @example s3.us-east-2.amazonaws.com
       */
      endpoint: string;
      /**
       * Verify Ssl
       * @description If enabled, SSL will be used to connect to s3. Boolean. Optional, defaults to true
       * @default true
       */
      verify_ssl: boolean;
      /**
       * Access Key
       * Format: password
       * @description S3 access key. Required.
       */
      access_key: string;
      /**
       * Secret Key
       * Format: password
       * @description S3 secret key. Required.
       */
      secret_key: string;
      /**
       * Bucket
       * @description S3 bucket name. Required.
       */
      bucket: string;
      /**
       * Key Prefix
       * @description Prefix for the object keys on s3. Optional, defaults to empty.
       * @default
       */
      key_prefix: string;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "s3";
    };
    /**
     * Script
     * @description Text script position.
     * @enum {string}
     */
    Script: "baseline" | "sub" | "super";
    /**
     * SectionHeaderItem
     * @description SectionItem.
     */
    SectionHeaderItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default section_header
       * @constant
       */
      label: "section_header";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
      /**
       * Level
       * @default 1
       */
      level: number;
    };
    /**
     * Size
     * @description Size.
     */
    Size: {
      /** Width */
      width?: number;
      /** Height */
      height?: number;
    };
    /**
     * TableCell
     * @description TableCell.
     */
    TableCell: {
      bbox?: components["schemas"]["BoundingBox"] | null;
      /**
       * Row Span
       * @default 1
       */
      row_span: number;
      /**
       * Col Span
       * @default 1
       */
      col_span: number;
      /** Start Row Offset Idx */
      start_row_offset_idx: number;
      /** End Row Offset Idx */
      end_row_offset_idx: number;
      /** Start Col Offset Idx */
      start_col_offset_idx: number;
      /** End Col Offset Idx */
      end_col_offset_idx: number;
      /** Text */
      text: string;
      /**
       * Column Header
       * @default false
       */
      column_header: boolean;
      /**
       * Row Header
       * @default false
       */
      row_header: boolean;
      /**
       * Row Section
       * @default false
       */
      row_section: boolean;
    };
    /**
     * TableData
     * @description BaseTableData.
     */
    TableData: {
      /**
       * Table Cells
       * @default []
       */
      table_cells: (
        | components["schemas"]["RichTableCell"]
        | components["schemas"]["TableCell"]
      )[];
      /**
       * Num Rows
       * @default 0
       */
      num_rows: number;
      /**
       * Num Cols
       * @default 0
       */
      num_cols: number;
      /**
       * Grid
       * @description grid.
       */
      readonly grid: components["schemas"]["TableCell"][][];
    };
    /**
     * TableFormerMode
     * @description Modes for the TableFormer model.
     * @enum {string}
     */
    TableFormerMode: "fast" | "accurate";
    /**
     * TableItem
     * @description TableItem.
     */
    TableItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default table
       * @enum {string}
       */
      label: "document_index" | "table";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /**
       * Captions
       * @default []
       */
      captions: components["schemas"]["RefItem"][];
      /**
       * References
       * @default []
       */
      references: components["schemas"]["RefItem"][];
      /**
       * Footnotes
       * @default []
       */
      footnotes: components["schemas"]["RefItem"][];
      image?: components["schemas"]["ImageRef"] | null;
      data: components["schemas"]["TableData"];
      /**
       * Annotations
       * @default []
       */
      annotations: (
        | components["schemas"]["DescriptionAnnotation"]
        | components["schemas"]["MiscAnnotation"]
      )[];
    };
    /**
     * TargetName
     * @enum {string}
     */
    TargetName: "inbody" | "zip";
    /** TaskProcessingMeta */
    TaskProcessingMeta: {
      /** Num Docs */
      num_docs: number;
      /**
       * Num Processed
       * @default 0
       */
      num_processed: number;
      /**
       * Num Succeeded
       * @default 0
       */
      num_succeeded: number;
      /**
       * Num Failed
       * @default 0
       */
      num_failed: number;
    };
    /** TaskStatusResponse */
    TaskStatusResponse: {
      /** Task Id */
      task_id: string;
      task_type: components["schemas"]["TaskType"];
      /** Task Status */
      task_status: string;
      /** Task Position */
      task_position?: number | null;
      task_meta?: components["schemas"]["TaskProcessingMeta"] | null;
    };
    /**
     * TaskType
     * @enum {string}
     */
    TaskType: "convert" | "chunk";
    /**
     * TextItem
     * @description TextItem.
     */
    TextItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @enum {string}
       */
      label:
        | "caption"
        | "checkbox_selected"
        | "checkbox_unselected"
        | "footnote"
        | "page_footer"
        | "page_header"
        | "paragraph"
        | "reference"
        | "text"
        | "empty_value";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
    };
    /**
     * TitleItem
     * @description TitleItem.
     */
    TitleItem: {
      /** Self Ref */
      self_ref: string;
      parent?: components["schemas"]["RefItem"] | null;
      /**
       * Children
       * @default []
       */
      children: components["schemas"]["RefItem"][];
      /** @default body */
      content_layer: components["schemas"]["ContentLayer"];
      /**
       * Label
       * @default title
       * @constant
       */
      label: "title";
      /**
       * Prov
       * @default []
       */
      prov: components["schemas"]["ProvenanceItem"][];
      /** Orig */
      orig: string;
      /** Text */
      text: string;
      formatting?: components["schemas"]["Formatting"] | null;
      /** Hyperlink */
      hyperlink?: string | null;
    };
    /**
     * TransformersModelType
     * @enum {string}
     */
    TransformersModelType:
      | "automodel"
      | "automodel-vision2seq"
      | "automodel-causallm"
      | "automodel-imagetexttotext";
    /** ValidationError */
    ValidationError: {
      /** Location */
      loc: (string | number)[];
      /** Message */
      msg: string;
      /** Error Type */
      type: string;
    };
    /** VlmModelApi */
    VlmModelApi: {
      /**
       * Url
       * Format: uri
       * @description Endpoint which accepts openai-api compatible requests.
       * @example http://localhost:8000/v1/chat/completions
       * @example http://localhost:1234/v1/chat/completions
       */
      url: string;
      /**
       * Headers
       * @description Headers used for calling the API endpoint. For example, it could include authentication headers.
       * @default {}
       */
      headers: {
        [key: string]: string;
      };
      /**
       * Params
       * @description Model parameters.
       * @default {}
       * @example {
       *       "max_completion_tokens": 800,
       *       "model": "ds4sd/SmolDocling-256M-preview"
       *     }
       * @example {
       *       "max_completion_tokens": 800,
       *       "model": "ibm-granite/granite-vision-3.3-2b"
       *     }
       */
      params: Record<string, never>;
      /**
       * Timeout
       * @description Timeout for the API request.
       * @default 60
       */
      timeout: number;
      /**
       * Concurrency
       * @description Maximum number of concurrent requests to the API.
       * @default 1
       * @example 1
       */
      concurrency: number;
      /**
       * Prompt
       * @description Prompt used when calling the vision-language model.
       * @default Convert this page to docling.
       * @example Convert this page to docling.
       * @example Convert this page to markdown. Do not miss any text and only output the bare markdown!
       */
      prompt: string;
      /**
       * Scale
       * @description Scale factor of the images used.
       * @default 2
       */
      scale: number;
      /** @description Type of response generated by the model. */
      response_format: components["schemas"]["ResponseFormat"];
    };
    /** VlmModelLocal */
    VlmModelLocal: {
      /**
       * Repo Id
       * @description Repository id from the Hugging Face Hub.
       */
      repo_id: string;
      /**
       * Prompt
       * @description Prompt used when calling the vision-language model.
       * @default Convert this page to docling.
       * @example Convert this page to docling.
       * @example Convert this page to markdown. Do not miss any text and only output the bare markdown!
       */
      prompt: string;
      /**
       * Scale
       * @description Scale factor of the images used.
       * @default 2
       */
      scale: number;
      /** @description Type of response generated by the model. */
      response_format: components["schemas"]["ResponseFormat"];
      /** @description Inference framework to use. */
      inference_framework: components["schemas"]["InferenceFramework"];
      /**
       * @description Type of transformers auto-model to use.
       * @default automodel
       */
      transformers_model_type: components["schemas"]["TransformersModelType"];
      /**
       * Extra Generation Config
       * @description Config from https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig
       * @default {
       *       "max_new_tokens": 800,
       *       "do_sample": false
       *     }
       * @example {
       *       "do_sample": false,
       *       "max_new_tokens": 800
       *     }
       */
      extra_generation_config: Record<string, never>;
    };
    /**
     * VlmModelType
     * @enum {string}
     */
    VlmModelType:
      | "smoldocling"
      | "smoldocling_vllm"
      | "granite_vision"
      | "granite_vision_vllm"
      | "granite_vision_ollama"
      | "got_ocr_2";
    /** ZipTarget */
    ZipTarget: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      kind: "zip";
    };
    /**
     * ocr_engines_enum
     * @enum {string}
     */
    ocr_engines_enum:
      | "easyocr"
      | "ocrmac"
      | "rapidocr"
      | "tesserocr"
      | "tesseract";
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}
export type $defs = Record<string, never>;
export interface operations {
  openapi_30_openapi_3_0_json_get: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": unknown;
        };
      };
    };
  };
  health_health_get: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HealthCheckResponse"];
        };
      };
    };
  };
  process_url_v1_convert_source_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["ConvertDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json":
            | components["schemas"]["ConvertDocumentResponse"]
            | components["schemas"]["PresignedUrlConvertDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  process_file_v1_convert_file_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_process_file_v1_convert_file_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json":
            | components["schemas"]["ConvertDocumentResponse"]
            | components["schemas"]["PresignedUrlConvertDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  process_url_async_v1_convert_source_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["ConvertDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  process_file_async_v1_convert_file_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_process_file_async_v1_convert_file_async_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_sources_with_HybridChunker_as_async_task_v1_chunk_hybrid_source_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["HybridChunkerOptionsDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_files_with_HybridChunker_as_async_task_v1_chunk_hybrid_file_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_Chunk_files_with_HybridChunker_as_async_task_v1_chunk_hybrid_file_async_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_sources_with_HybridChunker_v1_chunk_hybrid_source_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["HybridChunkerOptionsDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChunkDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_files_with_HybridChunker_v1_chunk_hybrid_file_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_Chunk_files_with_HybridChunker_v1_chunk_hybrid_file_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChunkDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_sources_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_source_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["HierarchicalChunkerOptionsDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_files_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_file_async_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_Chunk_files_with_HierarchicalChunker_as_async_task_v1_chunk_hierarchical_file_async_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_sources_with_HierarchicalChunker_v1_chunk_hierarchical_source_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["HierarchicalChunkerOptionsDocumentsRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChunkDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  Chunk_files_with_HierarchicalChunker_v1_chunk_hierarchical_file_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": components["schemas"]["Body_Chunk_files_with_HierarchicalChunker_v1_chunk_hierarchical_file_post"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChunkDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  task_status_poll_v1_status_poll__task_id__get: {
    parameters: {
      query?: {
        /** @description Number of seconds to wait for a completed status. */
        wait?: number;
      };
      header?: never;
      path: {
        task_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["TaskStatusResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  task_result_v1_result__task_id__get: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        task_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json":
            | components["schemas"]["ConvertDocumentResponse"]
            | components["schemas"]["PresignedUrlConvertDocumentResponse"]
            | components["schemas"]["ChunkDocumentResponse"];
          "application/zip": unknown;
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  clear_converters_v1_clear_converters_get: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ClearResponse"];
        };
      };
    };
  };
  clear_results_v1_clear_results_get: {
    parameters: {
      query?: {
        older_then?: number;
      };
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ClearResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
}
